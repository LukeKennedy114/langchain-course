{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamurAIGPT/langchain-course/blob/main/models/Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-dBjFwloRjWm"
      },
      "source": [
        "# Models\n",
        "\n",
        "In the previous lesson we have covered the basics of Langchain. Here is the link to the first lesson https://github.com/SamurAIGPT/langchain-course/blob/main/getting-started/Introduction.ipynb\n",
        "\n",
        "In this lesson we will talk about different kinds of models including LLMs, Chat Models and Embedding Models\n",
        "\n",
        "### What is a model ?\n",
        "\n",
        "A model is a program which is trained to complete a specific task. Since our course is about language tasks the models we will be using are language models. A model is trained on a huge corpus of data\n",
        "\n",
        "We are not going to cover the process of training as we are going to use already trained models. These pre-trained models are trained on large amounts of data and require a lot of compute to run and thus are called Large Language Models (LLM)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "D39TvmO0XwVq"
      },
      "source": [
        "# 1. LLM (Large Language Model)\n",
        "\n",
        "Now let's talk about LLM. LLM are trained to do language tasks like text generation. There are various LLM in the market but we are going to cover only OpenAI LLM since they are the most popular. OpenAI has 4 such models Davinci, Curie, Ada and Babbage\n",
        "\n",
        "##### Here is how you can use OpenAI LLM in langchain\n",
        "\n",
        "##### Let's install necessary libraries and acquire the OPENAI API KEY from the .env file.\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxpekH8sY51F",
        "outputId": "5612d231-3814-4cff-a58e-45261c85237f"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install tiktoken\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv \n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY2ySwxrR6FA",
        "outputId": "ef7623ac-3d45-4fde-9c52-505145cad3b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Q: Why don't scientists trust atoms?\n",
            "A: Because they make up everything!\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "llm = OpenAI(temperature=1, openai_api_key = openai_api_key)\n",
        "print(llm(\"Tell me a joke\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rE2dyU_7jFdQ"
      },
      "source": [
        "### Estimating number of tokens\n",
        "\n",
        "OpenAI models have a context length limiting the size of input data which can be sent to the model. Thus we need to make sure the input text is below that limit before sending to the model. We can do that calculation using the code below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJ8nKBryZJ05",
        "outputId": "8517fd34-08a1-4bd2-cb25-38fbe30b5bbf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.get_num_tokens(\"what a joke\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "39MZ8q1vkRmy"
      },
      "source": [
        "### Streaming\n",
        "\n",
        "Streaming is a major concept in LLM which allows you to display output on the go instead of waiting for the full output. Even in the ChatGPT interface you will see content streamed instead of waiting till entire output is generated\n",
        "\n",
        "Here is a code example for the same. We handle streaming in langchain using a callback handler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg_l58n4jelZ",
        "outputId": "ab2c4ab4-0ee6-4cb1-b171-8bef5e9a65ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Beauty is a thing of wonder,\n",
            "A sight that can't be denied.\n",
            "It's a feeling that can't be measured,\n",
            "A feeling that can't be denied.\n",
            "\n",
            "It's a thing of beauty that can't be seen,\n",
            "But can be felt in the heart and soul.\n",
            "It's a thing of beauty that can't be touched,\n",
            "But can be seen in the eyes of the beholder.\n",
            "\n",
            "Beauty is a thing of joy,\n",
            "A thing that can't be taken away.\n",
            "It's a thing of beauty that can't be bought,\n",
            "But can be found in the simplest of things.\n",
            "\n",
            "Beauty is a thing of love,\n",
            "A thing that can't be denied.\n",
            "It's a thing of beauty that can't be measured,\n",
            "But can be seen in the love of others.\n",
            "\n",
            "Beauty is a thing of life,\n",
            "A thing that can't be taken away.\n",
            "It's a thing of beauty that can't be bought,\n",
            "But can be found in the simplest of things."
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "llm = OpenAI(streaming=True, callbacks=[StreamingStdOutCallbackHandler()], temperature=0, openai_api_key=openai_api_key)\n",
        "resp = llm(\"Write me a poem on beauty.\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a6POXNT5lISE"
      },
      "source": [
        "# 2. Chat Models\n",
        "\n",
        "The second set of models we are going to cover are the chat models. The famous ChatGPT model GPT-3.5 comes under this. The main difference between the previous LLM models and the Chat Models are\n",
        "\n",
        "* Chat Models are 10x cheaper for api calls\n",
        "* You can hold a conversation with a chat model like you can with a human which is not possible with the previous LLMs\n",
        "\n",
        "Since Chat Models can hold a conversation they take a list of chat messages as input instead of plain text like a LLM\n",
        "\n",
        "Now let's discuss how we can use these Chat Models. Let's do the necessary imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-vt0WitNkGbO"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PQCg5peknI4v"
      },
      "source": [
        "Instead of using a OpenAI class we will be using a ChatOpenAI class to create our chat LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HvNAJfqJnETc"
      },
      "outputs": [],
      "source": [
        "chat = ChatOpenAI(temperature=0, openai_api_key=openai_api_key)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tJwiLHVWnbvj"
      },
      "source": [
        "Input is a bunch of messages. Messages are classified into 3 types\n",
        "\n",
        "* System Message - This is an initial prompt sent to the model to control the behavior of the model\n",
        "\n",
        "* Human Message  - Input message of the user\n",
        "\n",
        "* AI Message     - Message response given by ChatGPT\n",
        "\n",
        "ChatGPT needs a list of all these messages in the conversation to be able to understand the content and converse further\n",
        "\n",
        "Now let's see an example where we define the system message and the message input of the user and pass to the chat model. The output generated will be an AI message\n",
        "\n",
        "We are using a System Prompt to let the model do the task of paraphrasing. This technique of providing the model a prompt to make it perform a task is called Prompt Engineering and can be part of another lesson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhyJTCHJnPb2",
        "outputId": "0a2e7b23-239a-466a-8df8-e0f4868f796f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='I have a strong passion for coding.', additional_kwargs={}, example=False)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant that paraphrases the sentence.\"),\n",
        "    HumanMessage(content=\"I love programming.\")\n",
        "]\n",
        "chat(messages)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2WldCk-so6O0"
      },
      "source": [
        "# Templates in Chat Models\n",
        "\n",
        "We have discussed templates in lesson 1 which helps us to create dynamic inputs. We can do the same with Chat Models as well. Let's discuss the code for that\n",
        "\n",
        "We define a system message with input variable task. This task can be dynamically change to do various tasks. For this example we will follow the task of paraphrasing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1JWLOxwoIYE",
        "outputId": "d0748e8f-63a2-4124-a12f-f51cdcc00c9d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='I have a strong passion for coding.', additional_kwargs={}, example=False)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "template=\"You are a helpful assistant that {task}.\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "human_template=\"{text}\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
        "chat(chat_prompt.format_prompt(task=\"paraphrases the sentence\", text=\"I love programming.\").to_messages())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2b-ipRktpzc8"
      },
      "source": [
        "Just like how we used the LLMChain or SequentialChain for LLMs in lesson 1, we can do the same for Chat Models. Thus all the benefits we talked like chaining multiple tasks for LLMs can be achieved with Chat Models as well Here is an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hBTlMb7XpZ_x",
        "outputId": "ee9a7415-5394-492d-da95-a8c379bc7f8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I have a strong passion for coding.'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
        "chain.run(task=\"paraphrases the sentence\", text=\"I love programming.\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1gnDNh7tqRi0"
      },
      "source": [
        "### Streaming with Chat Models\n",
        "\n",
        "We disucussed about how streaming is useful in the above section of LLMs. Now let's see how we can do the same with Chat Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BElza6zoqL5k",
        "outputId": "107d9bcb-a852-4e8b-83d0-02ee5d51e3e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In the realm of beauty, let us embark,\n",
            "Where nature's wonders ignite a spark.\n",
            "A tapestry woven with colors so grand,\n",
            "A symphony of grace, across the land.\n",
            "\n",
            "Behold the sunrise, a celestial dance,\n",
            "As golden rays upon the earth enhance.\n",
            "The sky ablaze with hues of crimson fire,\n",
            "A masterpiece that fills our hearts' desire.\n",
            "\n",
            "The moon, a pearl, adorns the velvet night,\n",
            "Casting its glow, a beacon of pure light.\n",
            "Stars twinkle like diamonds, a celestial choir,\n",
            "Guiding our dreams, igniting our desire.\n",
            "\n",
            "In every flower, a secret is concealed,\n",
            "Petals unfurl, their fragrant love revealed.\n",
            "A delicate ballet, as they sway and bloom,\n",
            "Their vibrant beauty, a sweet, divine perfume.\n",
            "\n",
            "The mountains rise, majestic and serene,\n",
            "Their peaks touch the heavens, a sight unseen.\n",
            "Cloaked in mist, they stand with silent grace,\n",
            "A testament to nature's perfect embrace.\n",
            "\n",
            "The ocean's vastness, a mesmerizing sight,\n",
            "Its waves crashing, a symphony of might.\n",
            "Endless depths, where mysteries reside,\n",
            "A captivating beauty, impossible to hide.\n",
            "\n",
            "But true beauty lies not in what we see,\n",
            "It dwells within, in hearts that long to be,\n",
            "Kind, compassionate, and filled with love,\n",
            "A beauty that shines, like stars above.\n",
            "\n",
            "For beauty is not confined to form or face,\n",
            "It's found in acts of kindness, love's embrace.\n",
            "In every smile, a touch, a gentle word,\n",
            "A beauty that's felt, and forever heard.\n",
            "\n",
            "So let us cherish beauty, in all its forms,\n",
            "In nature's wonders, and in hearts that warm.\n",
            "For in this world, where chaos may reside,\n",
            "Beauty is the light, our eternal guide."
          ]
        }
      ],
      "source": [
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "chat = ChatOpenAI(streaming=True, callbacks=[StreamingStdOutCallbackHandler()], temperature=0, openai_api_key=openai_api_key)\n",
        "resp = chat([HumanMessage(content=\"Write me a poem on beauty.\")])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "I8Jm6gWhq5wG"
      },
      "source": [
        "# Embedding models\n",
        "\n",
        "So far we have talked about text generation models but now we are going to talk about a completely different kind of model called Embedding models\n",
        "\n",
        "### Embeddings\n",
        "\n",
        "First we need to understand what is an embedding. An embedding is generally associated with a piece of text and it represents the properties of text\n",
        "\n",
        "Just to give an example, let's consider the words good, best, bad. If we find the embeddings of these words we observe that embeddings of good and best are close while embedding of bad is far. The reason being embedding of a word has knowledge of the meaning of the word. Thus words with similar meanings have similar embeddings\n",
        "\n",
        "Embeddings also have an interesting as can be seen below. Let's consider E(x) as Embedding of word x\n",
        "\n",
        "E(king) - E(male) + E(female) ~= E(queen)\n",
        "\n",
        "What this represents is if we subtract the embedding of word male from word king and add the embedding of word female it will be quite close to embedding of word queen. As humans we can understand this intuitively as removing male gender and adding female gender to king makes it a queen but now machines have the capability to understand such complex relations"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BIeDJtVKtLN6"
      },
      "source": [
        "### Use-cases\n",
        "\n",
        "Now that we have an idea of what is embeddings, the task of a embeddings model is to create these embeddings for the text input provided. A model which generates embedding which can show properties like the ones we discussed above and more is considered a good model.\n",
        "\n",
        "Once these embeddings are generated, we can use it to perform tasks like semantic search similar to how apps like Chatbase, PDF.ai, SiteGPT work. You can creating embeddings for all your documents or webpages and when user asks a query you can fetch the relevant pieces and send to the user\n",
        "\n",
        "Now let's discuss it with the help of an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BXNAymAqqiY3"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "text = \"This is dummy content.\"\n",
        "doc_result = embeddings.embed_documents([text])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lLnrb5VJu3Gx"
      },
      "source": [
        "As you can see, the output is a vector which is a respresentation of text \"This is dummy content\". To identify if two sentences are similar, we can calculate the distance between these vectors. If the distance is small, then the words are of similar meanings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gKfYPHIuoLg",
        "outputId": "de4666a5-281b-47a4-c9d5-1b800003bb03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0.009624725285748391,\n",
              "  0.005727740051113911,\n",
              "  -0.025073372030961615,\n",
              "  -0.009651258666114387,\n",
              "  -0.01194633366916001,\n",
              "  0.014234776724098007,\n",
              "  -0.03536804794148363,\n",
              "  -0.02598874850787875,\n",
              "  -0.01833407409457965,\n",
              "  -0.03796824843683496,\n",
              "  0.0040395986616420234,\n",
              "  0.0073362826964716845,\n",
              "  -0.015587942801183084,\n",
              "  0.009505328799391739,\n",
              "  -0.007289850677815065,\n",
              "  -0.00630482524159042,\n",
              "  0.0176442248315154,\n",
              "  -0.021876184447214113,\n",
              "  0.010752364148980578,\n",
              "  -0.01796261608268153,\n",
              "  -0.0033945231973768458,\n",
              "  0.005207036198439332,\n",
              "  -0.009737489823997417,\n",
              "  0.01796261608268153,\n",
              "  -0.013272967297201673,\n",
              "  -0.007953167026174605,\n",
              "  0.019673973481481727,\n",
              "  -0.027222518098607176,\n",
              "  0.014168445135828182,\n",
              "  -0.004908543585563829,\n",
              "  0.03130855064155098,\n",
              "  -0.020722014997583676,\n",
              "  -0.00595326773062809,\n",
              "  -0.03709267109914424,\n",
              "  0.011468745861088238,\n",
              "  0.0009352765703992915,\n",
              "  0.004540402944703397,\n",
              "  -0.0366681481891593,\n",
              "  0.01699417470767757,\n",
              "  0.001897085822672642,\n",
              "  -0.02090774307221015,\n",
              "  0.007230151968975447,\n",
              "  0.003208794657089078,\n",
              "  -0.04255840216821654,\n",
              "  -0.014818495259666015,\n",
              "  -0.009299700223829473,\n",
              "  -0.0013556535232867272,\n",
              "  -0.030698297794294394,\n",
              "  -0.0012321107887942587,\n",
              "  0.016834978150771923,\n",
              "  0.01578693849731514,\n",
              "  -0.0067094485819621606,\n",
              "  -0.03343116146618538,\n",
              "  -0.0105202031243749,\n",
              "  -0.0019750255320219443,\n",
              "  0.011966233238773216,\n",
              "  -0.013770454674886651,\n",
              "  0.020841410552617744,\n",
              "  0.01048040398514849,\n",
              "  -0.0003177701754191428,\n",
              "  -0.01824121005726641,\n",
              "  -0.005004724528253462,\n",
              "  -0.006997991410031061,\n",
              "  -0.022194577561025403,\n",
              "  0.0009186936733318352,\n",
              "  -0.009531861248435152,\n",
              "  -0.004271759686247702,\n",
              "  -0.006384423520043243,\n",
              "  0.001722965170633706,\n",
              "  0.0074026147504028,\n",
              "  0.018625933828024945,\n",
              "  0.009107338338450207,\n",
              "  -0.0037610058512103717,\n",
              "  -0.028230758612837546,\n",
              "  0.024728447399429494,\n",
              "  0.0015911309876075095,\n",
              "  -0.024953974613282384,\n",
              "  0.010354373688039048,\n",
              "  0.007614875739733982,\n",
              "  -0.011064122520716499,\n",
              "  0.022552767951417942,\n",
              "  -0.04608724676199059,\n",
              "  -0.02519276944864085,\n",
              "  0.018493270651485292,\n",
              "  0.031414680437724635,\n",
              "  0.01814834601995317,\n",
              "  0.022300707357199058,\n",
              "  0.0309370907670077,\n",
              "  -0.0036150759844877237,\n",
              "  -0.012888243526443138,\n",
              "  -0.015826737636541553,\n",
              "  0.01732583171770411,\n",
              "  0.017418697617662515,\n",
              "  0.013564827030646967,\n",
              "  -0.01141568096300141,\n",
              "  0.03576603560845741,\n",
              "  0.001475879701648769,\n",
              "  0.019329048849949605,\n",
              "  -0.014924625987162252,\n",
              "  -0.04706895389585496,\n",
              "  -0.012397389028188368,\n",
              "  0.0005012187216104383,\n",
              "  -0.014831761949849014,\n",
              "  0.003246935343627292,\n",
              "  -0.029902316872411332,\n",
              "  -0.016662515835005862,\n",
              "  -0.0005426759642790788,\n",
              "  -0.0025438196232106945,\n",
              "  0.028575683244369668,\n",
              "  0.01369085732775641,\n",
              "  -0.004576885178553413,\n",
              "  0.004334774834802423,\n",
              "  -0.004633267447677926,\n",
              "  -0.042133879258231595,\n",
              "  -0.004613367878064721,\n",
              "  0.01578693849731514,\n",
              "  -0.011170253248212735,\n",
              "  -0.006271659447455508,\n",
              "  0.0035984930874202676,\n",
              "  -0.01208563065645245,\n",
              "  0.002706332154170153,\n",
              "  0.023600809467519888,\n",
              "  0.0159594008130812,\n",
              "  -0.023547742706787896,\n",
              "  0.007581709945599069,\n",
              "  0.007163820380705623,\n",
              "  -0.006185428289572478,\n",
              "  -0.022539502192557525,\n",
              "  0.01301427382355258,\n",
              "  -0.004391156638265645,\n",
              "  0.01796261608268153,\n",
              "  0.01672884835459827,\n",
              "  0.007269951108201859,\n",
              "  0.026108145925557984,\n",
              "  -0.01627779206424733,\n",
              "  0.03457206888224573,\n",
              "  -0.019567843685308072,\n",
              "  0.007847036298678368,\n",
              "  -0.02488764395633514,\n",
              "  0.006341307941101728,\n",
              "  -0.00315241262079521,\n",
              "  0.027355181275146825,\n",
              "  -0.025259100105588093,\n",
              "  -0.00873588125787467,\n",
              "  0.007555177496555656,\n",
              "  0.015601209491366081,\n",
              "  -0.008742514137304879,\n",
              "  -0.012503519755684605,\n",
              "  0.0003432664116745705,\n",
              "  -0.023149753177168948,\n",
              "  -0.0107855294774542,\n",
              "  0.016038999091534025,\n",
              "  0.02163739147450081,\n",
              "  -0.012297892111444922,\n",
              "  0.007482212563194332,\n",
              "  0.032263726257694525,\n",
              "  0.012231560523175098,\n",
              "  -0.009113971217880415,\n",
              "  -0.002346482845428126,\n",
              "  -0.005488945681416733,\n",
              "  -0.007269951108201859,\n",
              "  0.009240001514989857,\n",
              "  0.0006616584195402954,\n",
              "  -0.013651058188529998,\n",
              "  0.024927441232916386,\n",
              "  0.02242010477487829,\n",
              "  0.02549789494094656,\n",
              "  0.002547136295756444,\n",
              "  -0.016781913252685098,\n",
              "  -0.022804828545636823,\n",
              "  -0.023481412049840653,\n",
              "  0.020270958707232733,\n",
              "  -0.01885146104187783,\n",
              "  0.02377327178328595,\n",
              "  -0.02929206588779991,\n",
              "  0.007369448490606597,\n",
              "  0.005830553873233752,\n",
              "  0.007309750247428271,\n",
              "  -0.016609450936919037,\n",
              "  -0.011647841987607089,\n",
              "  -0.032582115646215486,\n",
              "  0.00017899187659730972,\n",
              "  0.005820604088427149,\n",
              "  0.029424729064339558,\n",
              "  -0.009080805889406794,\n",
              "  0.010241610081112603,\n",
              "  0.012967841804895961,\n",
              "  -0.004719498605560957,\n",
              "  -0.011952967479912799,\n",
              "  -0.0008938192695229896,\n",
              "  0.029265534370079078,\n",
              "  0.02831035689129037,\n",
              "  -0.006536986266196099,\n",
              "  -0.005210352638154436,\n",
              "  -0.6911229547287807,\n",
              "  -0.0024642215775885173,\n",
              "  0.009777288031901246,\n",
              "  -0.01627779206424733,\n",
              "  0.008258293449802898,\n",
              "  0.027434779553599648,\n",
              "  0.007767438951548128,\n",
              "  0.002409497993982847,\n",
              "  -0.02126593346260269,\n",
              "  0.011853469631846771,\n",
              "  -0.01087839444609002,\n",
              "  -0.009511961678821946,\n",
              "  0.013637791498347,\n",
              "  -0.0054425136627601145,\n",
              "  0.011468745861088238,\n",
              "  -0.015879802534628378,\n",
              "  0.0017262817267641327,\n",
              "  -0.006112463356211154,\n",
              "  -0.018572868929938115,\n",
              "  0.03194533314388324,\n",
              "  0.005157287274406318,\n",
              "  0.010181911372272985,\n",
              "  -0.02043015526413838,\n",
              "  0.007435780544537713,\n",
              "  -0.009770655152471039,\n",
              "  0.0031391463962735034,\n",
              "  -0.001421156118043099,\n",
              "  -0.004918493370370432,\n",
              "  0.009299700223829473,\n",
              "  0.027620507628226123,\n",
              "  -0.016436988621152976,\n",
              "  0.008974675161910558,\n",
              "  -0.006596684509374425,\n",
              "  0.0031175886068027458,\n",
              "  0.04112563688135606,\n",
              "  0.0127953794891299,\n",
              "  -0.010904926895133435,\n",
              "  -0.005432563877953512,\n",
              "  0.001466759143186265,\n",
              "  0.010613067161688139,\n",
              "  -0.030353373162762272,\n",
              "  0.003518895274628736,\n",
              "  0.024184527071765313,\n",
              "  -0.008895076883457734,\n",
              "  -0.02710312068092794,\n",
              "  -0.01319336901874885,\n",
              "  0.0009551760818048358,\n",
              "  0.0066464334334074395,\n",
              "  0.004822312427680798,\n",
              "  0.015667541079635906,\n",
              "  -0.001522311836720711,\n",
              "  -0.003198844872282475,\n",
              "  -0.0021043722688464904,\n",
              "  -0.003741106281597166,\n",
              "  -0.015388948036373609,\n",
              "  0.0040429155670184186,\n",
              "  0.020987341350662974,\n",
              "  0.012118795984926071,\n",
              "  0.016237992925020917,\n",
              "  0.012821911938173313,\n",
              "  -0.010175278492842778,\n",
              "  0.005820604088427149,\n",
              "  -0.01801568284341352,\n",
              "  -0.0037013073752014,\n",
              "  -0.0014460304636442832,\n",
              "  -0.020098496391466672,\n",
              "  -0.0021176387261988426,\n",
              "  0.01824121005726641,\n",
              "  0.012802012368560108,\n",
              "  -0.022857893443723652,\n",
              "  -0.0013689198642237567,\n",
              "  0.03531498118075164,\n",
              "  -0.00691176025214803,\n",
              "  -0.0023696988547564357,\n",
              "  -0.009565026576908773,\n",
              "  0.020655682477991266,\n",
              "  0.030432971441215095,\n",
              "  -0.00613236292582436,\n",
              "  -0.022088445902206585,\n",
              "  0.019819904279526956,\n",
              "  0.009969649917280513,\n",
              "  -0.006978091840417855,\n",
              "  -0.013969450371018708,\n",
              "  -0.010082414455529539,\n",
              "  0.020708747376078095,\n",
              "  -0.01828100919649282,\n",
              "  -0.03374955457999667,\n",
              "  -0.0024078397741252953,\n",
              "  0.023163018936029362,\n",
              "  0.0031209050465178497,\n",
              "  0.025869351090199517,\n",
              "  0.0023531159576889796,\n",
              "  -0.011661107746467505,\n",
              "  -0.01672884835459827,\n",
              "  0.012967841804895961,\n",
              "  0.021292466842968684,\n",
              "  0.007522011702420743,\n",
              "  0.017007440466537984,\n",
              "  0.017219701921530457,\n",
              "  -0.011296283545322175,\n",
              "  -0.010758997028410787,\n",
              "  0.010361007498791838,\n",
              "  -0.015561410352139671,\n",
              "  0.009724223133814418,\n",
              "  0.03451900212151374,\n",
              "  0.016914576429224747,\n",
              "  -0.0012354273449246853,\n",
              "  0.027753170804765775,\n",
              "  0.018586134688798533,\n",
              "  -0.024754978917150325,\n",
              "  0.004755980839410973,\n",
              "  -0.012563218464524222,\n",
              "  0.0049781920792100484,\n",
              "  0.01163457529742409,\n",
              "  -0.022260908217972646,\n",
              "  -0.03581910236918941,\n",
              "  0.012675982071450665,\n",
              "  -0.002059598470047423,\n",
              "  0.010400805706695666,\n",
              "  -0.001955125962408739,\n",
              "  0.028708348283554484,\n",
              "  0.024012064755999252,\n",
              "  0.02366714012446713,\n",
              "  0.007661308224051892,\n",
              "  -0.018294274955353237,\n",
              "  0.02054955268181761,\n",
              "  0.021478194917595162,\n",
              "  0.0025073371565300325,\n",
              "  -0.028841011460094133,\n",
              "  -0.0038008047576061376,\n",
              "  -0.004437588656922264,\n",
              "  -0.0030844228126678335,\n",
              "  0.03130855064155098,\n",
              "  -0.012934675545099758,\n",
              "  0.025829553813618268,\n",
              "  0.014712364532169779,\n",
              "  -0.007323016471949977,\n",
              "  0.017856486286507874,\n",
              "  0.03170653830852477,\n",
              "  -0.0014062314408331946,\n",
              "  -0.019143320775323127,\n",
              "  0.00041830409075400364,\n",
              "  -0.0037477393938580195,\n",
              "  -0.013584726600260173,\n",
              "  -0.001559623413330149,\n",
              "  -0.03714573785987623,\n",
              "  -0.0263867380374977,\n",
              "  0.011621308607241093,\n",
              "  0.022194577561025403,\n",
              "  0.0021690456372587636,\n",
              "  -0.021836387170632864,\n",
              "  0.014818495259666015,\n",
              "  -0.007966433716357604,\n",
              "  0.01070593213032396,\n",
              "  -0.02073528075644409,\n",
              "  -0.004046232006733523,\n",
              "  -0.000990829322141399,\n",
              "  -0.02060261757990444,\n",
              "  0.0018340706741179211,\n",
              "  0.009160404167859616,\n",
              "  0.006838795318786706,\n",
              "  0.019435180508768423,\n",
              "  -0.009213469065946443,\n",
              "  0.010274776340908806,\n",
              "  -0.023879401579459603,\n",
              "  0.013418897163924321,\n",
              "  -0.008948142712867143,\n",
              "  0.0011856786537223166,\n",
              "  0.0009128896127920964,\n",
              "  -0.037384528969944375,\n",
              "  -0.007263318228771651,\n",
              "  0.003455880126074015,\n",
              "  0.0028472868956588536,\n",
              "  0.00027983673725929224,\n",
              "  -0.006384423520043243,\n",
              "  0.009505328799391739,\n",
              "  -0.027275582996694,\n",
              "  -0.002703015714455049,\n",
              "  0.002683116144841843,\n",
              "  -0.005989749964478107,\n",
              "  -0.007555177496555656,\n",
              "  0.01907698825573072,\n",
              "  -0.008974675161910558,\n",
              "  0.0011069097180289153,\n",
              "  0.01431437500255083,\n",
              "  0.00975738846228804,\n",
              "  -0.002759397517918271,\n",
              "  0.020005632354153435,\n",
              "  -0.010487036864578697,\n",
              "  0.0012802012601390753,\n",
              "  0.00910070545902,\n",
              "  0.011694274006263708,\n",
              "  0.0022503019027384926,\n",
              "  0.011880002080890184,\n",
              "  -0.01832080833571923,\n",
              "  0.0033895483049735443,\n",
              "  -0.03512925310612516,\n",
              "  0.01970050686184772,\n",
              "  0.00588361923698187,\n",
              "  0.004891960921327018,\n",
              "  0.021053672007610217,\n",
              "  0.005611659538811072,\n",
              "  0.023521211189067064,\n",
              "  -0.020483220162225205,\n",
              "  -0.0019285933969500025,\n",
              "  -0.03685387626378577,\n",
              "  -0.010089047334959748,\n",
              "  -0.0005323116827157494,\n",
              "  0.015840003395401966,\n",
              "  0.004228644107306187,\n",
              "  -0.0005634046438210606,\n",
              "  -0.015866534913122798,\n",
              "  0.018771862763425008,\n",
              "  0.004086031145959934,\n",
              "  -0.003973267073372199,\n",
              "  -0.0042982921352911155,\n",
              "  -0.007369448490606597,\n",
              "  0.011753971783780742,\n",
              "  -0.0046067345329732215,\n",
              "  -0.004095980930766537,\n",
              "  0.01573387173658315,\n",
              "  -0.034386337082328924,\n",
              "  -0.0030744730278612306,\n",
              "  -0.006997991410031061,\n",
              "  0.004676383026619441,\n",
              "  -0.00013960743785443978,\n",
              "  0.01577367087580956,\n",
              "  0.0258560853313391,\n",
              "  0.021491460676455576,\n",
              "  -0.03674774646761212,\n",
              "  0.0003596420312598328,\n",
              "  0.023003824241768882,\n",
              "  -0.0016093722209478403,\n",
              "  -0.007455679648489627,\n",
              "  -0.0025405029506649452,\n",
              "  -0.005346332720070481,\n",
              "  0.010460504415535284,\n",
              "  -0.00579738807909884,\n",
              "  0.02460904998175026,\n",
              "  -0.010162011802659781,\n",
              "  -0.008112363583080252,\n",
              "  0.020629149097625272,\n",
              "  0.036827344746064944,\n",
              "  0.01658291755655304,\n",
              "  0.03374955457999667,\n",
              "  0.007906735007517986,\n",
              "  0.014075581098514945,\n",
              "  0.006672966348112144,\n",
              "  0.010805429047067406,\n",
              "  0.027355181275146825,\n",
              "  -0.013518395011990349,\n",
              "  0.010533469814557899,\n",
              "  1.5663085050326196e-05,\n",
              "  0.00029641966343057916,\n",
              "  0.018957590838051486,\n",
              "  -0.030565634617754744,\n",
              "  -0.009531861248435152,\n",
              "  -0.009352766053238882,\n",
              "  0.024555985083663433,\n",
              "  0.016038999091534025,\n",
              "  0.022910960204455644,\n",
              "  -0.016330856962334155,\n",
              "  0.014553168906586715,\n",
              "  -0.014778696120439605,\n",
              "  0.03481085999231387,\n",
              "  0.0032336688862749396,\n",
              "  -0.024768246538655905,\n",
              "  0.0068719611129216185,\n",
              "  0.01149527831013165,\n",
              "  -0.020138295530693084,\n",
              "  -0.022101713523712162,\n",
              "  0.004566935393746811,\n",
              "  0.010546735573418314,\n",
              "  -0.01802894860227394,\n",
              "  0.004218694322499584,\n",
              "  0.007588343290690568,\n",
              "  0.012045831517226038,\n",
              "  0.017073772986130394,\n",
              "  0.011150353678599529,\n",
              "  0.02194251696680652,\n",
              "  -0.02759397611050529,\n",
              "  -0.03709267109914424,\n",
              "  -0.00452713672018169,\n",
              "  0.012404022838941159,\n",
              "  0.001139246402235052,\n",
              "  -0.0022867843694191546,\n",
              "  -0.03207799818306805,\n",
              "  -0.006241810093035699,\n",
              "  -0.0309370907670077,\n",
              "  0.0011889952098527432,\n",
              "  0.0015098747221277801,\n",
              "  0.014155178445645185,\n",
              "  0.014301108312367833,\n",
              "  -0.01601246571116803,\n",
              "  -0.0010414072396878664,\n",
              "  0.021332265982195096,\n",
              "  0.0034227143319391024,\n",
              "  0.007276584453293358,\n",
              "  -0.023441612910614244,\n",
              "  -0.005764222284963927,\n",
              "  0.010739097458797581,\n",
              "  0.005707840481500705,\n",
              "  0.01814834601995317,\n",
              "  -0.005787438294292237,\n",
              "  0.009160404167859616,\n",
              "  0.016742114113458686,\n",
              "  -0.007395981405311301,\n",
              "  0.007382715180789595,\n",
              "  0.0024177893261012524,\n",
              "  0.012098897346635447,\n",
              "  0.0003799560976297651,\n",
              "  0.01607879636811527,\n",
              "  -0.008198594740963282,\n",
              "  -7.451948537394813e-05,\n",
              "  0.01226472585164872,\n",
              "  -0.0036880409178490477,\n",
              "  -0.0008490454125162608,\n",
              "  0.007037790549257472,\n",
              "  0.015004224265615075,\n",
              "  0.005276684692085552,\n",
              "  -0.012291258300692132,\n",
              "  -0.008483820663655786,\n",
              "  -0.02096080797029698,\n",
              "  0.01597266657194162,\n",
              "  0.054922625867931285,\n",
              "  0.017206436162670043,\n",
              "  0.0031656790781475624,\n",
              "  0.010142112233046575,\n",
              "  0.008769046586348292,\n",
              "  -0.01493789267734525,\n",
              "  -0.027567442730139297,\n",
              "  0.0048123626428741954,\n",
              "  0.0024824626945135256,\n",
              "  -0.0074291471994462135,\n",
              "  -0.015760405116949146,\n",
              "  0.012755580349903489,\n",
              "  0.0107855294774542,\n",
              "  -0.012848444387216728,\n",
              "  0.021823119549127284,\n",
              "  -0.013339298885471498,\n",
              "  -0.003353066071123528,\n",
              "  -0.00807256444385384,\n",
              "  -0.008145528911553871,\n",
              "  -0.01867899872611177,\n",
              "  -0.0025670356325390043,\n",
              "  0.006643116993692335,\n",
              "  -0.0008681157557853678,\n",
              "  -0.001145050520982452,\n",
              "  0.02109347114683663,\n",
              "  -0.005561910614778057,\n",
              "  0.0187320636241986,\n",
              "  0.010513570244944693,\n",
              "  0.011037590071673084,\n",
              "  -0.019567843685308072,\n",
              "  -0.012463720616458193,\n",
              "  0.007953167026174605,\n",
              "  0.011137087919739113,\n",
              "  0.022738497888689584,\n",
              "  -0.018824927661511837,\n",
              "  0.019647441963760896,\n",
              "  0.002366382415041332,\n",
              "  -0.008304725468459518,\n",
              "  0.016662515835005862,\n",
              "  -0.008583318511721815,\n",
              "  0.0021159802735106455,\n",
              "  0.01968723924034214,\n",
              "  8.586842228919114e-05,\n",
              "  -0.0133724651452677,\n",
              "  0.02955739224087921,\n",
              "  -0.022035381004119756,\n",
              "  -0.0034525634535282654,\n",
              "  0.02643980479822969,\n",
              "  -0.005160604179782713,\n",
              "  -0.019859701556108205,\n",
              "  0.010288042099769221,\n",
              "  -0.011030957192242877,\n",
              "  -0.012901510216626137,\n",
              "  -0.013597992359120589,\n",
              "  0.021212868564515864,\n",
              "  0.010493670675331487,\n",
              "  -0.005127438385647801,\n",
              "  0.009286434464969058,\n",
              "  -0.0159594008130812,\n",
              "  -0.029424729064339558,\n",
              "  -0.016224727166160503,\n",
              "  -0.005183820189111022,\n",
              "  -0.009359398932669091,\n",
              "  0.004862111566907209,\n",
              "  -0.02657246797476934,\n",
              "  -0.03780905187992932,\n",
              "  0.0026068347717654156,\n",
              "  -0.00474603105460437,\n",
              "  -0.019143320775323127,\n",
              "  0.01061970097244093,\n",
              "  0.0020148244384177103,\n",
              "  -0.0037908549727995347,\n",
              "  0.006337991035725333,\n",
              "  0.0009128896127920964,\n",
              "  0.012404022838941159,\n",
              "  -0.0046697496815279425,\n",
              "  -0.003860503233615109,\n",
              "  -0.010798796167637199,\n",
              "  0.0026814579249842914,\n",
              "  0.014420505730047066,\n",
              "  0.00018282667008896744,\n",
              "  -0.05364905713797645,\n",
              "  -0.0082450267596199,\n",
              "  -0.025630558117486213,\n",
              "  -0.004616684317779824,\n",
              "  0.015296083067737788,\n",
              "  -0.004241910331827893,\n",
              "  0.005216985983245935,\n",
              "  -0.006938292701191444,\n",
              "  0.021876184447214113,\n",
              "  -0.0026648747950861894,\n",
              "  0.008954775592297352,\n",
              "  0.005356282504877084,\n",
              "  -0.015879802534628378,\n",
              "  0.022871161065229233,\n",
              "  0.014287841622184834,\n",
              "  0.021318998360689515,\n",
              "  -0.012828544817603522,\n",
              "  0.01038753994783525,\n",
              "  0.008457288214612373,\n",
              "  -0.011037590071673084,\n",
              "  -0.010639600542054135,\n",
              "  0.00033994982644031314,\n",
              "  0.005558594175062954,\n",
              "  0.016397189481926564,\n",
              "  -0.01686151153113792,\n",
              "  0.0006740955923408875,\n",
              "  -0.0010314574548812635,\n",
              "  0.0005642337537498366,\n",
              "  -0.009724223133814418,\n",
              "  -0.014685832083126366,\n",
              "  -0.007342916041563183,\n",
              "  -0.008742514137304879,\n",
              "  -0.008463921094042582,\n",
              "  0.0048256293330571935,\n",
              "  -0.005137388170454403,\n",
              "  0.005621609323617675,\n",
              "  0.019647441963760896,\n",
              "  -0.014261309173141421,\n",
              "  -0.016569651797692625,\n",
              "  -0.003482412807948074,\n",
              "  -0.03319236663082691,\n",
              "  0.013717389776799824,\n",
              "  0.010911559774563642,\n",
              "  0.0027925633120531837,\n",
              "  0.01297447468432617,\n",
              "  -0.0193555822303156,\n",
              "  -0.019196385673409953,\n",
              "  -0.01408884685737536,\n",
              "  0.022910960204455644,\n",
              "  -0.025975482749018335,\n",
              "  0.0010049247730072044,\n",
              "  -0.012921409786239343,\n",
              "  -0.019023923357643892,\n",
              "  -0.014951158436205666,\n",
              "  0.009737489823997417,\n",
              "  -0.003976583513087302,\n",
              "  0.010453871536105075,\n",
              "  -0.00771437358780001,\n",
              "  -0.015455279624643433,\n",
              "  -0.0032784429179046524,\n",
              "  0.009425730520938915,\n",
              "  0.012649449622407253,\n",
              "  -0.021478194917595162,\n",
              "  -0.005933368161014884,\n",
              "  -0.030963624147373695,\n",
              "  -0.0127953794891299,\n",
              "  -0.008052664874240634,\n",
              "  -0.009379298502282297,\n",
              "  0.006785729955038588,\n",
              "  0.026413271417863694,\n",
              "  0.008742514137304879,\n",
              "  -0.009890052570150272,\n",
              "  -0.028336890271656364,\n",
              "  0.0060394988885111205,\n",
              "  -0.022260908217972646,\n",
              "  -0.006792363300130087,\n",
              "  0.0029036689319527215,\n",
              "  0.03382915285844949,\n",
              "  0.02555095983903339,\n",
              "  0.03985206815140122,\n",
              "  -0.011355982254161793,\n",
              "  0.026598999492490172,\n",
              "  0.02261910047101035,\n",
              "  -0.001191482656054394,\n",
              "  -0.001211382109252277,\n",
              "  0.016330856962334155,\n",
              "  -0.0002823241834609429,\n",
              "  -0.029981915150864156,\n",
              "  0.0067293481515753656,\n",
              "  0.003162362405601813,\n",
              "  0.021478194917595162,\n",
              "  0.011097288780512702,\n",
              "  0.015362415587330196,\n",
              "  -0.004434272217207161,\n",
              "  0.007177087070888621,\n",
              "  0.0019866335366860994,\n",
              "  -0.004407739768163747,\n",
              "  -0.01756462655306258,\n",
              "  -0.022022115245259342,\n",
              "  -0.027726639287044944,\n",
              "  0.0014153519992956987,\n",
              "  -0.00891497645307094,\n",
              "  0.0296104590016112,\n",
              "  -0.023786537542146366,\n",
              "  -0.01573387173658315,\n",
              "  -0.010281409220339014,\n",
              "  0.03457206888224573,\n",
              "  0.012715781210677077,\n",
              "  -0.005966533955149797,\n",
              "  0.01590633405234921,\n",
              "  -0.016702314974232274,\n",
              "  0.004391156638265645,\n",
              "  -0.0035620108535702514,\n",
              "  -0.009180303737472821,\n",
              "  -0.022300707357199058,\n",
              "  0.010394172827265458,\n",
              "  -0.006195378074379081,\n",
              "  -0.003391206757661742,\n",
              "  0.007522011702420743,\n",
              "  -0.0011516836332433054,\n",
              "  -0.007210252865023533,\n",
              "  0.0015811812028009066,\n",
              "  0.007110755016957505,\n",
              "  -0.00479246307326099,\n",
              "  0.0016433671250115289,\n",
              "  -0.020708747376078095,\n",
              "  -0.01189990165050339,\n",
              "  0.0009800504274060202,\n",
              "  -0.010467138226288074,\n",
              "  -0.014473570628133894,\n",
              "  -0.026957191745527874,\n",
              "  -0.014632767185039539,\n",
              "  -0.027673572526312952,\n",
              "  0.0021060304887040426,\n",
              "  0.01867899872611177,\n",
              "  -0.015548143661956672,\n",
              "  0.009293067344399266,\n",
              "  0.002588593422009762,\n",
              "  -0.027050055782841115,\n",
              "  -0.010234977201682396,\n",
              "  -0.009982916607463511,\n",
              "  0.053542923616512465,\n",
              "  0.015296083067737788,\n",
              "  0.01922291905377595,\n",
              "  0.02265889961023676,\n",
              "  -0.020708747376078095,\n",
              "  -0.022234376700251815,\n",
              "  0.0032950258149721085,\n",
              "  -0.006706132142247056,\n",
              "  -0.004341407714232631,\n",
              "  0.02309668827908212,\n",
              "  0.02054955268181761,\n",
              "  -0.018824927661511837,\n",
              "  0.00579738807909884,\n",
              "  -0.016025731470028445,\n",
              "  0.017763622249194637,\n",
              "  0.01614512888770768,\n",
              "  -0.023070154898716125,\n",
              "  -0.011336082684548587,\n",
              "  0.014606233804673543,\n",
              "  0.0016392214589523262,\n",
              "  -0.003993166642985405,\n",
              "  -0.010938092223607056,\n",
              "  -0.03390875113690232,\n",
              "  0.009883418759397482,\n",
              "  -0.020974073729157394,\n",
              "  -0.017060505364624813,\n",
              "  -0.021318998360689515,\n",
              "  -0.0005617463657558472,\n",
              "  -0.03236985605386818,\n",
              "  0.0036283424418400764,\n",
              "  -0.016516586899605796,\n",
              "  0.024622315740610676,\n",
              "  -0.0039799004184636975,\n",
              "  -0.02110673876834221,\n",
              "  -0.02537849752326733,\n",
              "  -0.02915940271126026,\n",
              "  -0.023919200718686015,\n",
              "  0.001651658573545257,\n",
              "  0.006659699657929146,\n",
              "  0.01863919958688536,\n",
              "  0.003820704327219343,\n",
              "  -0.008138896032123664,\n",
              "  0.015269550618694375,\n",
              "  0.0030413072337263183,\n",
              "  -0.00293351828637253,\n",
              "  0.008483820663655786,\n",
              "  -0.009956384158420097,\n",
              "  0.02487437633482956,\n",
              "  -0.004643217232484529,\n",
              "  -0.0058637196673686645,\n",
              "  0.00829145877827652,\n",
              "  -0.008523619802882198,\n",
              "  0.01542874717560002,\n",
              "  -0.008536886493065197,\n",
              "  -0.010506936434191903,\n",
              "  -0.0028804529226244117,\n",
              "  -0.028071563918577066,\n",
              "  -0.006032865543419622,\n",
              "  0.002769347302724874,\n",
              "  -0.004265126341156203,\n",
              "  -0.013558193219894177,\n",
              "  -0.008172062291919868,\n",
              "  -0.012277992541831716,\n",
              "  -0.011176887058965523,\n",
              "  -0.020668948236851684,\n",
              "  0.0023779904197054865,\n",
              "  -0.013206635708931847,\n",
              "  -0.0395071435198691,\n",
              "  -0.018347339853440062,\n",
              "  -0.011316183114935381,\n",
              "  0.00022034552418059934,\n",
              "  0.010108946904572954,\n",
              "  -0.0035852268628985607,\n",
              "  -0.0073362826964716845,\n",
              "  0.019859701556108205,\n",
              "  0.02679799518862223,\n",
              "  -0.027726639287044944,\n",
              "  0.003946734624328785,\n",
              "  -0.014274575863324418,\n",
              "  0.007740906036843424,\n",
              "  -0.0048853275762355194,\n",
              "  0.009724223133814418,\n",
              "  0.005896885461503577,\n",
              "  -0.008769046586348292,\n",
              "  -0.002709648826715902,\n",
              "  -0.010427339087061662,\n",
              "  -0.015667541079635906,\n",
              "  -0.0377294536014765,\n",
              "  0.0073362826964716845,\n",
              "  0.005356282504877084,\n",
              "  -0.023826336681372778,\n",
              "  -0.010321208359565426,\n",
              "  0.026917392606301462,\n",
              "  0.0038173876546735938,\n",
              "  0.00788683543790478,\n",
              "  0.015680806838496323,\n",
              "  -0.0150705558538849,\n",
              "  0.01694110980959074,\n",
              "  0.001714673722099978,\n",
              "  -0.01938211374803643,\n",
              "  0.0075750770661688616,\n",
              "  -0.030432971441215095,\n",
              "  -0.0010845228186293818,\n",
              "  0.004789146633545886,\n",
              "  -0.0012959550472777556,\n",
              "  0.02045668678185921,\n",
              "  -0.023202818075255774,\n",
              "  -0.019952567456066606,\n",
              "  -0.009637991975931388,\n",
              "  0.016543118417326627,\n",
              "  0.014898093538118839,\n",
              "  -0.011568243709154265,\n",
              "  -0.027023522402475117,\n",
              "  -0.015030756714658488,\n",
              "  -0.014990957575432078,\n",
              "  0.010261509650725809,\n",
              "  0.0030545734582480247,\n",
              "  0.0068188957491735,\n",
              "  0.004620000757494929,\n",
              "  0.004394473077980749,\n",
              "  -0.022857893443723652,\n",
              "  0.017378898478436103,\n",
              "  -0.0010513570244944693,\n",
              "  0.0016873119302971429,\n",
              "  -0.014155178445645185,\n",
              "  -0.02141186426064792,\n",
              "  -0.027938900742037417,\n",
              "  -0.0041855285283646715,\n",
              "  0.0035586941810245016,\n",
              "  0.018347339853440062,\n",
              "  0.0219292512079461,\n",
              "  -0.02502030713287479,\n",
              "  -0.012231560523175098,\n",
              "  -0.002198894991678572,\n",
              "  -0.03088402586892087,\n",
              "  -0.016423720999647395,\n",
              "  -0.018267741574987242,\n",
              "  -0.010579901833214517,\n",
              "  0.018480003029979715,\n",
              "  -0.006012965973806416,\n",
              "  -0.0019103521636096715,\n",
              "  0.036084428722268705,\n",
              "  0.012078997777022241,\n",
              "  0.0215710589549084,\n",
              "  0.001218015337928453,\n",
              "  -0.004076081361153331,\n",
              "  0.012052464396656247,\n",
              "  0.0017461812963773385,\n",
              "  0.004573568738838309,\n",
              "  0.011077389210899496,\n",
              "  -0.004056181791540126,\n",
              "  -0.02073528075644409,\n",
              "  0.03563337429456293,\n",
              "  0.02158432657641398,\n",
              "  0.008178695171350076,\n",
              "  0.013558193219894177,\n",
              "  0.002082814479375733,\n",
              "  -0.011521811690497647,\n",
              "  -0.010546735573418314,\n",
              "  0.000971758978872292,\n",
              "  -0.007827137660387746,\n",
              "  0.0099431174682371,\n",
              "  0.019501511165715666,\n",
              "  -0.014473570628133894,\n",
              "  -0.010035981505550339,\n",
              "  0.0009866836560821963,\n",
              "  0.01784322052764746,\n",
              "  -0.0026996990419092997,\n",
              "  0.007920001697700983,\n",
              "  -0.0026532667904220347,\n",
              "  0.00900120761095397,\n",
              "  -0.0017130153858271031,\n",
              "  -0.030167645088135797,\n",
              "  -0.0028821111424819634,\n",
              "  -0.02862875000510166,\n",
              "  -0.020708747376078095,\n",
              "  0.003109297041853695,\n",
              "  0.0036316591143858257,\n",
              "  -0.030565634617754744,\n",
              "  0.007661308224051892,\n",
              "  0.018068747741500347,\n",
              "  -0.016516586899605796,\n",
              "  -0.008596584270582231,\n",
              "  0.015442012934460436,\n",
              "  -0.020350556985685556,\n",
              "  -0.020615883338764854,\n",
              "  -0.0012918092648032302,\n",
              "  -0.022207843319885817,\n",
              "  0.005435880317668615,\n",
              "  -0.006546936051002702,\n",
              "  0.011077389210899496,\n",
              "  -0.015030756714658488,\n",
              "  -0.0019004023788030688,\n",
              "  -0.018758597004564594,\n",
              "  -0.0028406537833980004,\n",
              "  -0.004062814670970334,\n",
              "  0.013299499746245086,\n",
              "  -0.006898494027626323,\n",
              "  -0.015309349757920787,\n",
              "  -0.012324424560488335,\n",
              "  -0.011952967479912799,\n",
              "  0.007926634577131192,\n",
              "  0.0056680413422742935,\n",
              "  -0.005309850486220465,\n",
              "  -0.005734372930544119,\n",
              "  -0.024582516601384264,\n",
              "  -0.00412251337980995,\n",
              "  0.0125300531360506,\n",
              "  -0.03504965482767234,\n",
              "  -0.04584845192663212,\n",
              "  0.014964425126388663,\n",
              "  0.012536686015480808,\n",
              "  -0.021491460676455576,\n",
              "  0.0296104590016112,\n",
              "  0.21618817921980094,\n",
              "  -0.00018904527104117886,\n",
              "  0.006480604462732877,\n",
              "  0.02460904998175026,\n",
              "  -2.3216085725865184e-05,\n",
              "  0.025975482749018335,\n",
              "  -0.010805429047067406,\n",
              "  -0.006410955969086657,\n",
              "  -0.013299499746245086,\n",
              "  0.0074291471994462135,\n",
              "  0.012556585585094013,\n",
              "  0.01765749059037582,\n",
              "  -0.013127037430479025,\n",
              "  -0.0024675382501342666,\n",
              "  -0.007183719950318829,\n",
              "  -0.00967115730440501,\n",
              "  -0.015309349757920787,\n",
              "  -0.009153770357106825,\n",
              "  -0.04640563615051155,\n",
              "  -0.025126436929048444,\n",
              "  -0.0018755280332018844,\n",
              "  0.005455779887281821,\n",
              "  0.016874777289998335,\n",
              "  -0.005717790266307308,\n",
              "  0.013127037430479025,\n",
              "  -0.02194251696680652,\n",
              "  -0.028018497157845074,\n",
              "  0.001759447637314368,\n",
              "  0.03345769670919654,\n",
              "  0.03443940384306091,\n",
              "  -0.010108946904572954,\n",
              "  -0.0006711935911748488,\n",
              "  0.00340944787458675,\n",
              "  0.012317791681058128,\n",
              "  -0.012516786445867603,\n",
              "  0.016211461407300086,\n",
              "  0.008278193019416104,\n",
              "  -0.0014534928022492354,\n",
              "  0.04147056151288818,\n",
              "  0.008603218081335021,\n",
              "  0.007966433716357604,\n",
              "  -0.020324023605319562,\n",
              "  0.011150353678599529,\n",
              "  -0.007250051538588653,\n",
              "  -0.008450655335182165,\n",
              "  0.012397389028188368,\n",
              "  ...]]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc_result"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMBl7pxTif57Wes1RNDVaTP",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
